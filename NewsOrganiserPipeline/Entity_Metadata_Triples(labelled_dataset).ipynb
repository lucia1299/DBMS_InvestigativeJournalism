{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lucia1299/DBMS_InvestigativeJournalism/blob/main/Entity_Metadata_Triples(labelled_dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35zidducLPRI",
        "outputId": "44c58128-d4d5-46cb-be11-774f862b15ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing WN_test.tsv with label"
      ],
      "metadata": {
        "id": "24s3Tpl0LJZT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_tsv(file_path, max_tokens=1000):\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "\n",
        "    sentences_words = []\n",
        "    sentences_tags = []\n",
        "    current_sentence_words = []\n",
        "    current_sentence_tags = []\n",
        "    sentence_enders = \".!?\"\n",
        "    list_sentences=[]\n",
        "    list_tags=[]\n",
        "\n",
        "    for line in lines:\n",
        "        token = line.strip()\n",
        "        if token:\n",
        "            word, tag = token.split('\\t')\n",
        "            current_sentence_words.append(word)\n",
        "            current_sentence_tags.append(tag)\n",
        "\n",
        "            if word in sentence_enders:\n",
        "                sentences_words.append(current_sentence_words)\n",
        "                sentences_tags.append(current_sentence_tags)\n",
        "                current_sentence_words = []\n",
        "                current_sentence_tags = []\n",
        "        else:\n",
        "            if current_sentence_words:\n",
        "                sentences_words.append(current_sentence_words)\n",
        "                sentences_tags.append(current_sentence_tags)\n",
        "                current_sentence_words = []\n",
        "                current_sentence_tags = []\n",
        "\n",
        "    if current_sentence_words:\n",
        "        sentences_words.append(current_sentence_words)\n",
        "        sentences_tags.append(current_sentence_tags)\n",
        "\n",
        "    for sentence in sentences_words:\n",
        "        list_sentences.append(sentence)\n",
        "    for tag_list in sentences_tags:\n",
        "        list_tags.append(tag_list)\n",
        "\n",
        "    return list_sentences, list_tags\n",
        "\n",
        "# Usage example\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/TESI/github/WN_test.tsv'\n",
        "list_sentences, list_tags = process_tsv(file_path)"
      ],
      "metadata": {
        "id": "9kkBcNMMvDgy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(list_sentences[1])\n",
        "print(list_tags[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CksdapU1EvXa",
        "outputId": "19b2d7bd-4b58-4c8a-fc72-c7183330adb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Il', 'presentatore', 'Valerio', 'Merola', 'è', 'entrato', 'nel', 'mirino', 'della', 'giustizia', 'italiana', ',', 'per', 'problemi', 'con', 'il', 'fisco', '.']\n",
            "['O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "titles = []\n",
        "title_count = 0\n",
        "\n",
        "for sentence in list_sentences:\n",
        "    if sentence[-1] not in \".;?!:\":\n",
        "        titles.append(sentence)\n",
        "        title_count += 1\n",
        "\n",
        "print(f\"Number of sentences appended to titles: {title_count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDtTqxk9_dRW",
        "outputId": "b23ab889-f5a6-4a2e-b40c-00285c634cc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of sentences appended to titles: 290\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_label(list_sentences, list_tags):\n",
        "    dataset_list = []\n",
        "    counterId = 0\n",
        "    titles = []\n",
        "\n",
        "    for sentence in list_sentences:\n",
        "        if sentence[-1] not in \".;?!:\":\n",
        "            titles.append(sentence)\n",
        "\n",
        "    for i, sentence in enumerate(list_sentences):\n",
        "        if sentence[-1] not in \".;?!:\":\n",
        "            articles_dict = {}\n",
        "            articles_dict['id'] = counterId\n",
        "            articles_dict['title'] = sentence\n",
        "            articles_dict['article'] = []\n",
        "            articles_dict['tags'] = []\n",
        "\n",
        "            for j in range(i + 1, len(list_sentences)):\n",
        "                if list_sentences[j] in titles:\n",
        "                    break\n",
        "                articles_dict['article'].append(list_sentences[j])\n",
        "                articles_dict['tags'].append(list_tags[j])\n",
        "\n",
        "            dataset_list.append(articles_dict)\n",
        "            counterId += 1\n",
        "\n",
        "    return dataset_list"
      ],
      "metadata": {
        "id": "rRUOYKRdELXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_list = create_dataset_label(list_sentences, list_tags)\n",
        "print(type(dataset_list[0]['tags'][1][0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNxRl7lOF6Kx",
        "outputId": "08b5fffd-2c3d-462e-e03c-905051edbdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'str'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset_list[1])\n",
        "print(type(dataset_list[1]))\n",
        "print(type(dataset_list))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3DuIwUyzN77",
        "outputId": "030152c2-f9bb-40ec-e470-7f745f33042e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'id': 1, 'title': ['Rivolta', 'del', 'pane', 'nel', 'Magreb', ',', '50', 'morti', 'in', 'Tunisia'], 'article': [['50', 'morti', 'in', 'Tunisia', ',', 'scontri', 'in', 'Algeria', 'e', 'tensioni', 'in', 'Marocco', ',', 'aumenti', 'di', 'prezzo', 'per', 'grano', ',', 'olio', ',', 'zucchero', ',', 'oltre', 'che', 'del', 'petrolio', '.'], ['La', 'sommossa', 'ricorda', 'quella', \"dell'\", 'assalto', 'al', 'forno', 'delle', 'grucce', ',', 'di', 'manzoniana', 'memoria', '.'], ['È', 'di', 'nuovo', 'la', '\"', 'rivolta', 'del', 'pane', '\"', ',', 'in', 'tutto', 'il', 'Magreb', '.'], [\"C'\", 'è', 'chi', 'ricorda', 'che', 'ciclicamente', 'si', 'ripetono', 'le', 'stesse', 'scene', ',', \"c'\", 'è', 'chi', 'invece', 'vede', \"l'\", 'inizio', 'di', 'un', 'periodo', 'sempre', 'più', 'negativo', 'sul', 'problema', 'alimentare', 'mondiale', '.'], ['I', 'paesi', 'produttori', 'ed', 'esportatori', 'di', 'grano', ',', 'come', 'la', 'Francia', ',', 'stanno', 'assumendo', 'un', 'atteggiamento', 'sempre', 'più', 'prudente', 'nel', 'promettere', 'la', 'consegna', 'di', 'partite', 'di', 'cereali', ',', 'riaffermando', 'la', 'necessità', 'di', 'ricostruire', 'gli', 'stock', '.'], ['I', 'prezzi', 'nel', 'frattempo', 'da', '100', 'euro', 'la', 'tonnellata', 'sono', 'già', 'saliti', 'al', 'doppio', 'e', \"c'\", 'è', 'anche', 'chi', 'prospetta', 'la', 'possibilità', 'di', 'ulteriori', 'rialzi', '.'], ['Ma', 'sulle', 'cause', 'del', 'fenomeno', \"c'\", 'è', 'ancora', 'incertezza', '.'], [\"C'\", 'è', 'chi', 'punta', 'più', 'il', 'dito', 'sui', 'fenomeni', 'speculativi', 'e', 'chi', 'invece', 'crede', 'che', 'esistano', 'cause', 'strutturali', \"nell'\", 'insufficienza', 'della', 'produzione', '.'], ['Dieci', 'anni', 'fa', 'il', 'premio', 'Nobel', 'professor', 'Amartya', 'Sen', \"nell'\", 'allocuzione', 'per', 'il', 'conferimento', 'della', 'laurea', 'honoris', 'causa', ',', 'conferita', \"dall'\", 'Università', 'di', 'Firenze', ',', 'era', 'enormemente', 'fiducioso', 'che', ',', 'nel', 'futuro', ',', 'il', 'problema', 'non', 'sarebbe', 'stato', 'produrre', 'più', 'alimenti', ',', 'ma', 'solo', 'quello', 'di', 'una', 'equa', 'distribuzione', 'tra', 'paesi', 'ricchi', 'e', 'paesi', 'poveri', 'e', 'tra', 'classi', 'sociali', \"all'\", 'interno', 'dello', 'stesso', 'paese', '.'], ['Già', 'allora', 'però', 'Norman', 'Borlaug', ',', 'il', 'grande', 'padre', 'della', 'Rivoluzione', 'verde', ',', 'che', 'era', 'stato', \"anch'\", 'esso', 'insignito', 'del', 'Premio', 'Nobel', ',', 'era', 'enormemente', 'più', 'pessimista', ':'], ['i', 'miglioramenti', 'genetici', 'così', 'rivoluzionari', 'nel', 'secolo', 'scorso', '(', 'basta', 'in', 'Italia', 'ricordare', 'le', 'Sementi', 'elette', 'di', 'Nazareno', 'Strampelli', ')', 'sono', 'vicine', 'al', 'punto', 'di', 'impossibilità', 'di', 'ulteriori', 'miglioramenti', '.']], 'tags': [['O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-ORG', 'I-ORG', 'I-ORG', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O'], ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-LOC', 'O', 'O', 'O', 'O', 'O', 'B-PER', 'I-PER', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']]}\n",
            "<class 'dict'>\n",
            "<class 'list'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Metadata Triples Section"
      ],
      "metadata": {
        "id": "KUjVyZ14L1Em"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_triples_labelled(dataset_list):\n",
        "\n",
        "    triples = []\n",
        "\n",
        "    for i in range(len(dataset_list)):\n",
        "        for j in range(len(dataset_list[i]['article'])):\n",
        "            sentence = dataset_list[i]['article'][j]\n",
        "            tags = dataset_list[i]['tags'][j]\n",
        "\n",
        "            current_group = []\n",
        "            current_tags = []\n",
        "\n",
        "            for idx, word in enumerate(sentence):\n",
        "                if tags[idx] != 'O':\n",
        "                    current_group.append(word)\n",
        "                    current_tags.append(tags[idx])\n",
        "\n",
        "                    # If the next tag is not an 'I-' tag, we have reached the end of the group\n",
        "                    if idx + 1 == len(tags) or not tags[idx + 1].startswith('I'):\n",
        "                        triple_entity = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
        "                            'object': current_tags[0].split('-')[1]\n",
        "                        }\n",
        "                        triple_article = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://purl.org/ontology/bibo/citedBy',\n",
        "                            'object': dataset_list[i]['id']\n",
        "                        }\n",
        "                        triples.append(triple_entity)\n",
        "                        triples.append(triple_article)\n",
        "                        current_group = []\n",
        "                        current_tags = []\n",
        "                else:\n",
        "                    if current_group:\n",
        "                        triple = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
        "                            'object': current_tags[0].split('-')[1]\n",
        "                        }\n",
        "                        triple_article = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://purl.org/ontology/bibo/citedBy',\n",
        "                            'object': dataset_list[i]['id']\n",
        "                        }\n",
        "                        triples.append(triple_entity)\n",
        "                        triples.append(triple_article)\n",
        "                        current_group = []\n",
        "                        current_tags = []\n",
        "\n",
        "    return triples"
      ],
      "metadata": {
        "id": "NdDtbd-mnAbD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "triples = generate_triples_labelled(dataset_list)"
      ],
      "metadata": {
        "id": "E0IEpH141FJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(triples[1]))\n",
        "print(triples[2])\n",
        "print(triples[3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wduuGxSOu2sX",
        "outputId": "7fb8f347-debd-420b-c8ba-ec23d86a6fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'dict'>\n",
            "{'subject': 'Merolone', 'predicate': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type', 'object': 'PER'}\n",
            "{'subject': 'Merolone', 'predicate': 'http://purl.org/ontology/bibo/citedBy', 'object': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "file_path = '/content/drive/MyDrive/Colab Notebooks/TESI/github/triples_withlabel.json'\n",
        "\n",
        "# Write to the JSON file in Google Drive\n",
        "with open(file_path, 'w') as file:\n",
        "    json.dump(triples, file, indent=4)"
      ],
      "metadata": {
        "id": "RsBPl8qPycF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate triples for the two articles only\n"
      ],
      "metadata": {
        "id": "oj5bunDFVfJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_example_triples_labelled(dataset_example):\n",
        "\n",
        "    triples = []\n",
        "\n",
        "    for j in range(len(dataset_example['article'])):\n",
        "          sentence = dataset_example['article'][j]\n",
        "          tags = dataset_example['tags'][j]\n",
        "\n",
        "          current_group = []\n",
        "          current_tags = []\n",
        "\n",
        "          for idx, word in enumerate(sentence):\n",
        "              if tags[idx] != 'O':\n",
        "                  current_group.append(word)\n",
        "                  current_tags.append(tags[idx])\n",
        "\n",
        "                  # If the next tag is not an 'I-' tag, we have reached the end of the group\n",
        "                  if idx + 1 == len(tags) or not tags[idx + 1].startswith('I'):\n",
        "                      triple_entity = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
        "                            'object': current_tags[0].split('-')[1]\n",
        "                        }\n",
        "                      triple_article = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://purl.org/ontology/bibo/citedBy',\n",
        "                            'object': dataset_example['id']\n",
        "                        }\n",
        "                      triples.append(triple_entity)\n",
        "                      triples.append(triple_article)\n",
        "                      current_group = []\n",
        "                      current_tags = []\n",
        "              else:\n",
        "                  if current_group:\n",
        "                      triple = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type',\n",
        "                            'object': current_tags[0].split('-')[1]\n",
        "                        }\n",
        "                      triple_article = {\n",
        "                            'subject': ' '.join(current_group),\n",
        "                            'predicate': 'http://purl.org/ontology/bibo/citedBy',\n",
        "                            'object': dataset_example['id']\n",
        "                        }\n",
        "                      triples.append(triple_entity)\n",
        "                      triples.append(triple_article)\n",
        "                      current_group = []\n",
        "                      current_tags = []\n",
        "    return triples"
      ],
      "metadata": {
        "id": "cNzP_CYAV9CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "first_article_triples = generate_example_triples_labelled(dataset_list[1])\n",
        "second_article_triples = generate_example_triples_labelled(dataset_list[5])\n",
        "\n",
        "print(len(first_article_triples))\n",
        "print(len(second_article_triples))"
      ],
      "metadata": {
        "id": "hqoJJ7I_ViDv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef0fee86-9a98-4d27-a93b-c27a22767ac3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20\n",
            "28\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "example_triples = generate_example_triples_labelled(dataset_list[1]) + generate_example_triples_labelled(dataset_list[5])\n",
        "print(len(example_triples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMVwNKY1eOI2",
        "outputId": "1e72d76b-63fa-4620-d1b3-b8e34f59afb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/Colab Notebooks/TESI/github/example_triples_withlabel.json'\n",
        "\n",
        "# Write to the JSON file in Google Drive\n",
        "with open(file_path, 'w') as file:\n",
        "    json.dump(example_triples, file, indent=4)"
      ],
      "metadata": {
        "id": "6KeIffOCeH11"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
